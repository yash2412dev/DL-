{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:49:21.436268Z","iopub.execute_input":"2022-11-28T02:49:21.437238Z","iopub.status.idle":"2022-11-28T02:49:26.625340Z","shell.execute_reply.started":"2022-11-28T02:49:21.437203Z","shell.execute_reply":"2022-11-28T02:49:26.624218Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\nRANDOM_SEED = 2021 \nTEST_PCT = 0.3\nLABELS = [\"Normal\",\"Fraud\"]","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:49:26.627111Z","iopub.execute_input":"2022-11-28T02:49:26.627784Z","iopub.status.idle":"2022-11-28T02:49:26.633219Z","shell.execute_reply.started":"2022-11-28T02:49:26.627751Z","shell.execute_reply":"2022-11-28T02:49:26.632494Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")\n#dataset.head\nprint(list(dataset.columns))\ndataset.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:50:54.901474Z","iopub.execute_input":"2022-11-28T02:50:54.901867Z","iopub.status.idle":"2022-11-28T02:50:59.205818Z","shell.execute_reply.started":"2022-11-28T02:50:54.901827Z","shell.execute_reply":"2022-11-28T02:50:59.204775Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.168375e-15</td>\n      <td>3.416908e-16</td>\n      <td>-1.379537e-15</td>\n      <td>2.074095e-15</td>\n      <td>9.604066e-16</td>\n      <td>1.487313e-15</td>\n      <td>-5.556467e-16</td>\n      <td>1.213481e-16</td>\n      <td>-2.406331e-15</td>\n      <td>...</td>\n      <td>1.654067e-16</td>\n      <td>-3.568593e-16</td>\n      <td>2.578648e-16</td>\n      <td>4.473266e-15</td>\n      <td>5.340915e-16</td>\n      <td>1.683437e-15</td>\n      <td>-3.660091e-16</td>\n      <td>-1.227390e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Break down of the Normal and Fraud Transactions\")\nprint(pd.value_counts(dataset['Class'], sort = True) )","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:51:25.078569Z","iopub.execute_input":"2022-11-28T02:51:25.078988Z","iopub.status.idle":"2022-11-28T02:51:25.089107Z","shell.execute_reply.started":"2022-11-28T02:51:25.078953Z","shell.execute_reply":"2022-11-28T02:51:25.087928Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Break down of the Normal and Fraud Transactions\n0    284315\n1       492\nName: Class, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"sc=StandardScaler()\ndataset['Time'] = sc.fit_transform(dataset['Time'].values.reshape(-1, 1))\ndataset['Amount'] = sc.fit_transform(dataset['Amount'].values.reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:51:42.086236Z","iopub.execute_input":"2022-11-28T02:51:42.086656Z","iopub.status.idle":"2022-11-28T02:51:42.100814Z","shell.execute_reply.started":"2022-11-28T02:51:42.086623Z","shell.execute_reply":"2022-11-28T02:51:42.099954Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nraw_data = dataset.values\n# The last element contains if the transaction is normal which is represented by a 0 and if fraud then 1\nlabels = raw_data[:, -1]\n# The other data points are the electrocadriogram data\ndata = raw_data[:, 0:-1]\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n    data, labels, test_size=0.2, random_state=2021\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:52:08.234923Z","iopub.execute_input":"2022-11-28T02:52:08.235754Z","iopub.status.idle":"2022-11-28T02:52:08.391965Z","shell.execute_reply.started":"2022-11-28T02:52:08.235710Z","shell.execute_reply":"2022-11-28T02:52:08.391163Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\nmin_val = tf.reduce_min(train_data)\nmax_val = tf.reduce_max(train_data)\ntrain_data = (train_data - min_val) / (max_val - min_val)\ntest_data = (test_data - min_val) / (max_val - min_val)\ntrain_data = tf.cast(train_data, tf.float32)\ntest_data = tf.cast(test_data, tf.float32)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:52:18.236757Z","iopub.execute_input":"2022-11-28T02:52:18.237547Z","iopub.status.idle":"2022-11-28T02:52:18.447410Z","shell.execute_reply.started":"2022-11-28T02:52:18.237502Z","shell.execute_reply":"2022-11-28T02:52:18.446144Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2022-11-28 02:52:18.254718: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_labels = train_labels.astype(bool)\ntest_labels = test_labels.astype(bool)\n\n#creating normal and fraud datasets\n\nnormal_train_data = train_data[~train_labels]\nnormal_test_data = test_data[~test_labels]\nfraud_train_data = train_data[train_labels]\nfraud_test_data = test_data[test_labels]\nprint(\" No. of records in Fraud Train Data=\",len(fraud_train_data))\nprint(\" No. of records in Normal Train data=\",len(normal_train_data))\nprint(\" No. of records in Fraud Test Data=\",len(fraud_test_data))\nprint(\" No. of records in Normal Test data=\",len(normal_test_data))","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:56:42.312881Z","iopub.execute_input":"2022-11-28T02:56:42.313289Z","iopub.status.idle":"2022-11-28T02:56:42.363704Z","shell.execute_reply.started":"2022-11-28T02:56:42.313256Z","shell.execute_reply":"2022-11-28T02:56:42.362467Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":" No. of records in Fraud Train Data= 389\n No. of records in Normal Train data= 227456\n No. of records in Fraud Test Data= 103\n No. of records in Normal Test data= 56859\n","output_type":"stream"}]},{"cell_type":"code","source":"nb_epoch = 50\nbatch_size = 64\ninput_dim = normal_train_data.shape[1] #num of columns, 30\nencoding_dim = 14\nhidden_dim_1 = int(encoding_dim / 2) #\nhidden_dim_2=4  \nlearning_rate = 1e-7","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:57:00.672489Z","iopub.execute_input":"2022-11-28T02:57:00.673637Z","iopub.status.idle":"2022-11-28T02:57:00.678609Z","shell.execute_reply.started":"2022-11-28T02:57:00.673596Z","shell.execute_reply":"2022-11-28T02:57:00.677655Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#input Layer\ninput_layer = tf.keras.layers.Input(shape=(input_dim, ))\n\n#Encoder\nencoder = tf.keras.layers.Dense(encoding_dim, activation=\"tanh\",                                \n                        activity_regularizer=tf.keras.regularizers.l2(learning_rate))(input_layer)\nencoder=tf.keras.layers.Dropout(0.2)(encoder)\nencoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\nencoder = tf.keras.layers.Dense(hidden_dim_2, activation=tf.nn.leaky_relu)(encoder)\n\n# Decoder\ndecoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\ndecoder=tf.keras.layers.Dropout(0.2)(decoder)\ndecoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(decoder)\ndecoder = tf.keras.layers.Dense(input_dim, activation='tanh')(decoder)\n\n#Autoencoder\nautoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\nautoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:57:14.953901Z","iopub.execute_input":"2022-11-28T02:57:14.954784Z","iopub.status.idle":"2022-11-28T02:57:15.977844Z","shell.execute_reply.started":"2022-11-28T02:57:14.954743Z","shell.execute_reply":"2022-11-28T02:57:15.977023Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 30)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 14)                434       \n_________________________________________________________________\ndropout (Dropout)            (None, 14)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 105       \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 32        \n_________________________________________________________________\ndense_3 (Dense)              (None, 7)                 35        \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 7)                 0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 14)                112       \n_________________________________________________________________\ndense_5 (Dense)              (None, 30)                450       \n=================================================================\nTotal params: 1,168\nTrainable params: 1,168\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"cp = tf.keras.callbacks.ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n                               mode='min', monitor='val_loss', verbose=2, save_best_only=True)\n# define our early stopping\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.0001,\n    patience=10,\n    verbose=1, \n    mode='min',\n    restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:57:33.938613Z","iopub.execute_input":"2022-11-28T02:57:33.938996Z","iopub.status.idle":"2022-11-28T02:57:33.945669Z","shell.execute_reply.started":"2022-11-28T02:57:33.938963Z","shell.execute_reply":"2022-11-28T02:57:33.944243Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(metrics=['accuracy'],\n                    loss='mean_squared_error',\n                    optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:57:43.515404Z","iopub.execute_input":"2022-11-28T02:57:43.515772Z","iopub.status.idle":"2022-11-28T02:57:43.529439Z","shell.execute_reply.started":"2022-11-28T02:57:43.515743Z","shell.execute_reply":"2022-11-28T02:57:43.528382Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\nhistory = autoencoder.fit(normal_train_data, normal_train_data,\n                    epochs=nb_epoch,\n                    batch_size=batch_size,\n                    shuffle=True,\n                    validation_data=(test_data, test_data),\n                    verbose=1,\n                    callbacks=[cp, early_stop]\n                    ).history\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T02:57:54.032608Z","iopub.execute_input":"2022-11-28T02:57:54.032990Z","iopub.status.idle":"2022-11-28T02:59:26.945263Z","shell.execute_reply.started":"2022-11-28T02:57:54.032960Z","shell.execute_reply":"2022-11-28T02:59:26.944037Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2022-11-28 02:57:54.100114: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n3554/3554 [==============================] - 9s 2ms/step - loss: 0.0040 - accuracy: 0.0347 - val_loss: 2.0345e-05 - val_accuracy: 0.0078\n\nEpoch 00001: val_loss improved from inf to 0.00002, saving model to autoencoder_fraud.h5\nEpoch 2/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9384e-05 - accuracy: 0.0728 - val_loss: 2.0075e-05 - val_accuracy: 0.2168\n\nEpoch 00002: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\nEpoch 3/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9507e-05 - accuracy: 0.0652 - val_loss: 2.0061e-05 - val_accuracy: 0.0251\n\nEpoch 00003: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\nEpoch 4/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9521e-05 - accuracy: 0.0650 - val_loss: 1.9898e-05 - val_accuracy: 0.0085\n\nEpoch 00004: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\nEpoch 5/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9089e-05 - accuracy: 0.0906 - val_loss: 1.9694e-05 - val_accuracy: 0.0347\n\nEpoch 00005: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\nEpoch 6/50\n3554/3554 [==============================] - 9s 2ms/step - loss: 1.9395e-05 - accuracy: 0.0712 - val_loss: 2.0260e-05 - val_accuracy: 0.1279\n\nEpoch 00006: val_loss did not improve from 0.00002\nEpoch 7/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9446e-05 - accuracy: 0.0640 - val_loss: 2.0412e-05 - val_accuracy: 0.0661\n\nEpoch 00007: val_loss did not improve from 0.00002\nEpoch 8/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9515e-05 - accuracy: 0.0611 - val_loss: 2.0208e-05 - val_accuracy: 0.0814\n\nEpoch 00008: val_loss did not improve from 0.00002\nEpoch 9/50\n3554/3554 [==============================] - 9s 2ms/step - loss: 1.9543e-05 - accuracy: 0.0588 - val_loss: 2.0246e-05 - val_accuracy: 0.1279\n\nEpoch 00009: val_loss did not improve from 0.00002\nEpoch 10/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.9420e-05 - accuracy: 0.0594 - val_loss: 2.0172e-05 - val_accuracy: 0.0420\n\nEpoch 00010: val_loss did not improve from 0.00002\nEpoch 11/50\n3554/3554 [==============================] - 8s 2ms/step - loss: 1.8887e-05 - accuracy: 0.0954 - val_loss: 1.8311e-05 - val_accuracy: 0.2367\n\nEpoch 00011: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\nRestoring model weights from the end of the best epoch.\nEpoch 00011: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(history['loss'], linewidth=2, label='Train')\nplt.plot(history['val_loss'], linewidth=2, label='Test')\nplt.legend(loc='upper right')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\n#plt.ylim(ymin=0.70,ymax=1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T03:05:49.565888Z","iopub.execute_input":"2022-11-28T03:05:49.566823Z","iopub.status.idle":"2022-11-28T03:06:16.929431Z","shell.execute_reply.started":"2022-11-28T03:05:49.566776Z","shell.execute_reply":"2022-11-28T03:06:16.928330Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"test_x_predictions = autoencoder.predict(test_data)\nmse = np.mean(np.power(test_data - test_x_predictions, 2), axis=1)\nerror_df = pd.DataFrame({'Reconstruction_error': mse,\n                        'True_class': test_labels})","metadata":{"execution":{"iopub.status.busy":"2022-11-28T03:08:24.415075Z","iopub.execute_input":"2022-11-28T03:08:24.415877Z","iopub.status.idle":"2022-11-28T03:08:26.270338Z","shell.execute_reply.started":"2022-11-28T03:08:24.415832Z","shell.execute_reply":"2022-11-28T03:08:26.269169Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"threshold_fixed =52\npred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\nerror_df['pred'] =pred_y\n\n# print Accuracy, precision and recall\nprint(\" Accuracy: \",accuracy_score(error_df['True_class'], error_df['pred']))\nprint(\" Recall: \",recall_score(error_df['True_class'], error_df['pred']))\nprint(\" Precision: \",precision_score(error_df['True_class'], error_df['pred']))","metadata":{"execution":{"iopub.status.busy":"2022-11-28T03:08:26.272377Z","iopub.execute_input":"2022-11-28T03:08:26.272747Z","iopub.status.idle":"2022-11-28T03:08:26.443175Z","shell.execute_reply.started":"2022-11-28T03:08:26.272713Z","shell.execute_reply":"2022-11-28T03:08:26.441097Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":" Accuracy:  0.9981917769741231\n Recall:  0.0\n Precision:  0.0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}